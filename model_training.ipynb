{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9359f6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import (\n",
    "    f1_score, roc_auc_score, average_precision_score, precision_recall_curve,\n",
    "    accuracy_score, classification_report\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f43e5d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ------------------- helpers -------------------\n",
    "def purged_splits(n_samples, n_splits=5, embargo=50):\n",
    "    fold_sizes = np.full(n_splits, n_samples // n_splits, dtype=int)\n",
    "    fold_sizes[: n_samples % n_splits] += 1\n",
    "    starts = np.cumsum(fold_sizes) - fold_sizes\n",
    "    for i in range(n_splits):\n",
    "        test_start = starts[i]\n",
    "        test_end   = test_start + fold_sizes[i]\n",
    "        train_end  = max(0, test_start - embargo)\n",
    "        train_idx  = np.arange(0, train_end)\n",
    "        test_idx   = np.arange(test_start, test_end)\n",
    "        if len(train_idx) == 0:\n",
    "            continue\n",
    "        yield train_idx, test_idx\n",
    "\n",
    "def coerce_numeric_df(X):\n",
    "    X = X.copy()\n",
    "    for c in X.columns:\n",
    "        if not np.issubdtype(X[c].dtype, np.number):\n",
    "            X[c] = pd.to_numeric(X[c], errors=\"coerce\")\n",
    "    return X.replace([np.inf, -np.inf], np.nan).fillna(0.0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3093d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('clean_dataset.csv')\n",
    "df.columns\n",
    "\n",
    "# ------------------- 1) build 3 targets (no leakage) -------------------\n",
    "df = df.copy()\n",
    "\n",
    "H = 20  # lookahead horizon\n",
    "coin_specs = {\n",
    "    \"btc\": \"bitcoin_return\",\n",
    "    \"eth\": \"ethereum_return\",\n",
    "    \"ltc\": \"litecoin_return\",\n",
    "}\n",
    "\n",
    "for c, ret_col in coin_specs.items():\n",
    "    fut = df[ret_col].shift(-H).rolling(H).sum()\n",
    "    df[f\"y_{c}\"] = (fut > 0).astype(int)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c2091d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------- 2) make lagged features -------------------\n",
    "# Use all columns except the labels as features, then lag by +1 so features are strictly past\n",
    "label_cols = [f\"y_{c}\" for c in coin_specs.keys()]\n",
    "X_lagged = df.drop(columns=label_cols, errors=\"ignore\").shift(1)\n",
    "\n",
    "# Build final modeling frame and drop NaNs from rolling/shift\n",
    "data = pd.concat([X_lagged, df[label_cols]], axis=1).dropna().reset_index(drop=True)\n",
    "X = coerce_numeric_df(data.drop(columns=label_cols))\n",
    "\n",
    "y_dict = {c: data[f\"y_{c}\"].astype(int).values for c in coin_specs.keys()}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ca1cce6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/Helia/lib/python3.13/site-packages/xgboost/callback.py:264: UserWarning: [13:23:35] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1758007651359/work/src/metric/auc.cc:324: Dataset is empty, or contains only positive or negative samples.\n",
      "  score: str = model.eval_set(evals, epoch, self.metric, self._output_margin)\n",
      "/opt/miniconda3/envs/Helia/lib/python3.13/site-packages/xgboost/callback.py:264: UserWarning: [13:23:36] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1758007651359/work/src/metric/auc.cc:324: Dataset is empty, or contains only positive or negative samples.\n",
      "  score: str = model.eval_set(evals, epoch, self.metric, self._output_margin)\n"
     ]
    }
   ],
   "source": [
    "# ------------------- 3) train 3 models with walk-forward + embargo -------------------\n",
    "results = {}\n",
    "models  = {}\n",
    "thresholds = {}\n",
    "\n",
    "for coin in [\"btc\", \"eth\", \"ltc\"]:\n",
    "    y = y_dict[coin]\n",
    "    n = len(X)\n",
    "\n",
    "    oof_proba = np.zeros(n, dtype=float)\n",
    "    oof_pred  = np.zeros(n, dtype=int)\n",
    "\n",
    "    for tr_idx, te_idx in purged_splits(n, n_splits=5, embargo=50):\n",
    "        # validation is the tail of the train slice\n",
    "        val_portion = max(1, int(0.2 * len(tr_idx)))\n",
    "        if len(tr_idx) <= val_portion:\n",
    "            continue\n",
    "        val_idx = tr_idx[-val_portion:]\n",
    "        tr_core = tr_idx[:-val_portion]\n",
    "\n",
    "        X_tr, y_tr = X.iloc[tr_core], y[tr_core]\n",
    "        X_val, y_val = X.iloc[val_idx], y[val_idx]\n",
    "        X_te,  y_te  = X.iloc[te_idx],  y[te_idx]\n",
    "\n",
    "        pos = (y_tr == 1).sum(); neg = (y_tr == 0).sum()\n",
    "        spw = max(1.0, neg / max(1, pos))\n",
    "\n",
    "        clf = XGBClassifier(\n",
    "            tree_method=\"hist\",\n",
    "            max_depth=6,\n",
    "            learning_rate=0.05,\n",
    "            n_estimators=2000,   # early stop governs\n",
    "            subsample=0.9,\n",
    "            colsample_bytree=0.9,\n",
    "            min_child_weight=3,\n",
    "            gamma=1.0,\n",
    "            reg_lambda=2.0,\n",
    "            scale_pos_weight=spw,\n",
    "            eval_metric=\"auc\",\n",
    "            random_state=42\n",
    "        )\n",
    "\n",
    "        clf.fit(\n",
    "            X_tr, y_tr,\n",
    "            eval_set=[(X_tr, y_tr), (X_val, y_val)],\n",
    "            verbose=False\n",
    "            # early_stopping_rounds=100\n",
    "        )\n",
    "\n",
    "        # choose threshold on the validation tail (skip if single-class val)\n",
    "        proba_val = clf.predict_proba(X_val)[:, 1]\n",
    "        best_t = 0.5\n",
    "        if y_val.min() != y_val.max():\n",
    "            prec, rec, th = precision_recall_curve(y_val, proba_val)\n",
    "            best_f1 = -1.0\n",
    "            for t in th:\n",
    "                f1 = f1_score(y_val, (proba_val >= t).astype(int))\n",
    "                if f1 > best_f1:\n",
    "                    best_f1, best_t = f1, t\n",
    "\n",
    "        proba_te = clf.predict_proba(X_te)[:, 1]\n",
    "        oof_proba[te_idx] = proba_te\n",
    "        oof_pred[te_idx]  = (proba_te >= best_t).astype(int)\n",
    "\n",
    "    # store per-coin metrics\n",
    "    acc = accuracy_score(y, oof_pred)\n",
    "    auc = roc_auc_score(y, oof_proba)\n",
    "    ap  = average_precision_score(y, oof_proba)\n",
    "    rep = classification_report(y, oof_pred, digits=3)\n",
    "\n",
    "    results[coin] = {\"accuracy\": acc, \"roc_auc\": auc, \"avg_precision\": ap, \"report\": rep}\n",
    "    thresholds[coin] = \"per-fold (selected on validation)\"  # note: threshold varies by fold\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "42b34058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== BTC ===\n",
      "OOF Accuracy: 0.611\n",
      "OOF ROC-AUC : 0.622\n",
      "OOF AP      : 0.511\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.771     0.423     0.546       383\n",
      "           1      0.541     0.844     0.659       308\n",
      "\n",
      "    accuracy                          0.611       691\n",
      "   macro avg      0.656     0.634     0.603       691\n",
      "weighted avg      0.669     0.611     0.597       691\n",
      "\n",
      "\n",
      "=== ETH ===\n",
      "OOF Accuracy: 0.621\n",
      "OOF ROC-AUC : 0.675\n",
      "OOF AP      : 0.557\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.812     0.438     0.569       395\n",
      "           1      0.536     0.865     0.661       296\n",
      "\n",
      "    accuracy                          0.621       691\n",
      "   macro avg      0.674     0.651     0.615       691\n",
      "weighted avg      0.694     0.621     0.609       691\n",
      "\n",
      "\n",
      "=== LTC ===\n",
      "OOF Accuracy: 0.580\n",
      "OOF ROC-AUC : 0.557\n",
      "OOF AP      : 0.571\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.615     0.324     0.425       330\n",
      "           1      0.569     0.814     0.670       361\n",
      "\n",
      "    accuracy                          0.580       691\n",
      "   macro avg      0.592     0.569     0.547       691\n",
      "weighted avg      0.591     0.580     0.553       691\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ------------------- 4) show results -------------------\n",
    "for coin in [\"btc\", \"eth\", \"ltc\"]:\n",
    "    print(f\"\\n=== {coin.upper()} ===\")\n",
    "    print(f\"OOF Accuracy: {results[coin]['accuracy']:.3f}\")\n",
    "    print(f\"OOF ROC-AUC : {results[coin]['roc_auc']:.3f}\")\n",
    "    print(f\"OOF AP      : {results[coin]['avg_precision']:.3f}\")\n",
    "    print(results[coin][\"report\"])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Helia",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
